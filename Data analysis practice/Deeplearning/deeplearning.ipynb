{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deeplearning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwXLQVhQMRJZ"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Flatten\n",
        "from tensorflow.keras.datasets import fashion_mnist # fashion mnist데이터 셋 불러오기\n",
        "import tensorflow.keras.layers as Layer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import keras, os"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlizYXm7Y8tq"
      },
      "source": [
        "Early stopping을 활용한 신경망 모델구현해보기\n",
        "\n",
        "- overfitting을 방지하기 위한 Early stopping을 활용하여 신경망 모델 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EduqisU6MqO6",
        "outputId": "a2584673-29b7-479e-eacf-9be0ee3a3505"
      },
      "source": [
        "# 데이터 불러오기\n",
        "(x_train, y_train),(x_test, y_test) = fashion_mnist.load_data()\n",
        "print(x_train.shape, x_test.shape)\n",
        "\n",
        "# 데이터 정규화\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "# 클래스 확인\n",
        "np.unique(y_train)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (10000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEX0fnO8NTRb",
        "outputId": "1bb002b2-cc6b-4a73-9abd-d4b270b8899c"
      },
      "source": [
        "# 기본 신경만 만들기\n",
        "\n",
        "# 모델 구성 확인\n",
        "model = Sequential([\n",
        "  Flatten(input_shape = (28, 28)), # 28 x 28 이미지 데이터를 펴주기 위해 Flatten사용\n",
        "  Dense(10, activation= 'softmax') # 클래스가 10개이므로 10개의 노드 생성\n",
        "])\n",
        "\n",
        "# 컴파일 하기\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_7 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjTqNGQQQ3Nc",
        "outputId": "1134eea5-993d-4df3-cd27-825588503ea4"
      },
      "source": [
        "# 모델 학습\n",
        "\n",
        "# 변수 설정 (soft coding 습관화)\n",
        "batch_size = 30\n",
        "epochs_max = 1\n",
        "\n",
        "# 학습시킨 데이터를 저장시키기 위한 코드\n",
        "checkpoint_filepath = 'FMbest.hdf5'\n",
        "\n",
        "# overfitting을 방지하기 위해서 학습 중 early stop을 실시해 주기 위한 코드 저장\n",
        "early_stop = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',  # 모니터링 하는 방법\n",
        "    min_delta = 0,  # 지정 숫자보다 작으면 조기종료 발생(min_delta < 0 은 값이 증가할때 조기종료)\n",
        "    patience=10, # 조기종료가 발생 후에 몇 번 더 epoch를 진행 할지\n",
        "    verbose=1 # 자세한 정보 제공 (1이면 제공)\n",
        "    ) \n",
        "\n",
        "# Validation Set을 기준으로 가장 최적의 모델을 찾는 코드\n",
        "save_best = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath = checkpoint_filepath, monitor = 'val_loss', verbose = 1, \n",
        "    save_best_only = True, save_weights_only = True, mode = 'auto', save_freq = 'epoch',\n",
        "    option = None\n",
        ")\n",
        "\n",
        "# 모델 학습 코드 + early stop + Best model\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs= epochs_max,\n",
        "          verbose = 1, validation_data = (x_test, y_test),\n",
        "          callbacks = [early_stop, save_best])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 3s 2ms/step - loss: 0.6011 - accuracy: 0.7972 - val_loss: 0.5113 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.51133, saving model to FMbest.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2dd7250790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0QW9_4NYg0L",
        "outputId": "bc0620b0-6dcc-4142-c73f-7ce3755fac3f"
      },
      "source": [
        "# 학습된 모델을 이용하여 테스트하는 코드\n",
        "\n",
        "model.predict(x_test[0:1])\n",
        "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 0s - loss: 0.5113 - accuracy: 0.8227\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIU1iCJrYuG7"
      },
      "source": [
        "# 체크포인트에 저장된 가중치들을 불러들이는 코드\n",
        "\n",
        "model.load_weights(checkpoint_filepath)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwqAGQiuYx2T",
        "outputId": "28b6320e-f563-4aa0-f940-c48670da4fc3"
      },
      "source": [
        "# best model을 이용한 테스트 데이터 예측 정확도 재확인 코드\n",
        "\n",
        "model.predict(x_test[0:1])\n",
        "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.5113 - accuracy: 0.8227\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1-ThuSRY__I"
      },
      "source": [
        "Weight Decay 가중치 감소시키기\n",
        "\n",
        "- 학습과정에서 overfitting을 방지하기 위한 기술, Regularization의 한 종류인 Weight Decay를 활용한 신경망 구현하기\n",
        "- L1norm 과 L2 norm활용\n",
        "- costfunction에 람다를 더해줌으로서 비용함수가 더큰거처럼보여 가중치를 감소하게 만들기 위해 학습시키는 방법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbME9t2TYz1t",
        "outputId": "cff6401e-cfa4-4e3d-b088-6d11b3073535"
      },
      "source": [
        "# Weight Decay를 전체적으로 반영한 예시 코드\n",
        "from tensorflow.keras.constraints import MaxNorm\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# 모델 구성을 확인\n",
        "model = Sequential([\n",
        "  Flatten(input_shape=(28, 28)),\n",
        "  Dense(64,\n",
        "        kernel_regularizer = regularizers.l2(0.01), # L2 norm regularization\n",
        "        activity_regularizer = regularizers.l1(0.01)),\n",
        "        Dense(10, activation='softmax') # L1 norm regularization\n",
        "])\n",
        "\n",
        "# 업데이트 방식을 설정합니다.\n",
        "model.compile(optimizer='adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics =['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(x_train, y_train, batch_size= 30, epochs = 1, verbose = 1, \n",
        "          validation_data = (x_test, y_test)) \n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_8 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.0218 - accuracy: 0.7980 - val_loss: 0.8155 - val_accuracy: 0.7988\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2dd2677f50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIpax4-6cFMa"
      },
      "source": [
        "Constraints 를 활용한 신경망 구현하기\n",
        "- overfitting을 방지하기 위해 강제로 가중치의 상한선을 지정해 그 이상은 일정한 값으로 치환시킨다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzoT8j73b4qc",
        "outputId": "c23d13b7-9524-450e-c253-b3fdd2bb3725"
      },
      "source": [
        "# 모델 구성하기\n",
        "model = Sequential([\n",
        "                    Flatten(input_shape = (28, 28)),\n",
        "                    Dense(64, kernel_regularizer = regularizers.l2(0.01),\n",
        "                          activity_regularizer=regularizers.l1(0.01),\n",
        "                          kernel_constraint = MaxNorm(2.)), # add constraints\n",
        "                    Dense(10, activation = 'softmax') \n",
        "])\n",
        "\n",
        "# 업데이트 방식을 설정합니다.\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "model.fit(x_train, y_train, \n",
        "          batch_size= 30, epochs = 1,\n",
        "          verbose = 1, validation_data =(x_test, y_test))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_9 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 1.0296 - accuracy: 0.7947 - val_loss: 0.8089 - val_accuracy: 0.8098\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2dd25f7cd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiMyg4-6tykw"
      },
      "source": [
        "Dropout 을 활용한 신경망 구현하기\n",
        "- dropout을 사용하면 overfitting을 방지할 수 있다.\n",
        "- 일부 노드를 학습할때에만 차단 해줌으로서 일부 노드가 없이 결과를 예측하도록 만들고, 학습을 진행하기 때문에 과적합을 어느정도 차단할 수 있다. 즉, 노드를 임시로 몇개를 차단하여 강하게 키우는 느낌, test할때는 다시 노드를 사용하며, 랜덤으로 노드를 차단한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92OIYYe5tx0d",
        "outputId": "450d8bac-7070-4717-a91e-68eea53562fc"
      },
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.constraints import MaxNorm\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# 모델 구성을 확인합니다.\n",
        "model = Sequential([\n",
        "  Flatten(input_shape =(28,28)),\n",
        "  Dense(64,\n",
        "        kernel_regularizer = regularizers.l2(0.01),\n",
        "        activity_regularizer = regularizers.l1(0.01),\n",
        "        kernel_constraint=MaxNorm(2.))    ,\n",
        "  Dropout(0.5),\n",
        "  Dense(10, activation = 'softmax')\n",
        "])\n",
        "\n",
        "# 업데이트 방식을 설정합니다.\n",
        "model.compile(optimizer='adam'\n",
        "             , loss='sparse_categorical_crossentropy'\n",
        "             , metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(x_train, y_train, batch_size = 30, epochs =1, verbose = 1, \n",
        "          validation_data = (x_test, y_test))\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_10 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 1.2124 - accuracy: 0.7677 - val_loss: 0.8928 - val_accuracy: 0.8067\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2dd2396cd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qnp1iujlIzU1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWhef6hex9Fz",
        "outputId": "4f730135-7d91-4911-f5ab-b20e57a6499b"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "kf = KFold(n_splits = 5)             \n",
        "skf = StratifiedKFold(n_splits = 5, random_state = 100, shuffle = True) \n",
        "\n",
        "x_train.shape\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNBQ2lQRMqci",
        "outputId": "56fd14db-483c-4706-9318-95877c5dbc75"
      },
      "source": [
        "for train_index, val_index in kf.split(np.zeros(x_train.shape[0]), y_train):\n",
        "  print(train_index)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[12000 12001 12002 ... 59997 59998 59999]\n",
            "[    0     1     2 ... 59997 59998 59999]\n",
            "[    0     1     2 ... 59997 59998 59999]\n",
            "[    0     1     2 ... 59997 59998 59999]\n",
            "[    0     1     2 ... 47997 47998 47999]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}